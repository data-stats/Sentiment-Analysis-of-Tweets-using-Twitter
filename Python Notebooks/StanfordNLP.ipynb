{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StanfordNLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aalR6TYvHYVD",
        "colab_type": "text"
      },
      "source": [
        "**Predict the sentiment of tweets using Stanford CoreNLP library**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rIUeZD1G40f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEUPD6UOG4rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('last.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8OpXGP5G4qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " pd.options.display.max_colwidth = 250"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVGqK_48G4mF",
        "colab_type": "code",
        "outputId": "dadf3b54-2022-4d8a-cba0-7b6074a24f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "df.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>tagged_usernames</th>\n",
              "      <th>Text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>data</th>\n",
              "      <th>pol_sub</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>11:47:00</td>\n",
              "      <td>['#bjp', '#rss']</td>\n",
              "      <td>['@any_morya:']</td>\n",
              "      <td>['big', 'shame', 'bjp', 'rss', 'tried', 'divide', 'hindu', 'muslim', 'sunlight', 'heat', 'keeping', 'daily', 'ramzan', 'fasting']</td>\n",
              "      <td>['big', 'shame', 'bjp', 'rss', 'tried', 'divide', 'hindu', 'muslim', 'sunlight', 'heat', 'keeping', 'daily', 'ramzan', 'fasting']</td>\n",
              "      <td>its big shame to bjp rss who tried to divide hindu muslim  in such sunlight and heat keeping their daily ramzan fasting</td>\n",
              "      <td>Sentiment(polarity=0.0, subjectivity=0.19999999999999998)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        Date  ... polarity subjectivity\n",
              "0           0  2020-05-20  ...      0.0          0.2\n",
              "\n",
              "[1 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwUPDZFtG4Z8",
        "colab_type": "code",
        "outputId": "49cef495-a569-4e78-e96e-9e6b9b13dd49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "pip install pycorenlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycorenlp\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/40/e74eb4fc7906d630b73a84c9ae9d824f694bd4c5a1d727b8e18beadff613/pycorenlp-0.3.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pycorenlp) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp) (1.24.3)\n",
            "Building wheels for collected packages: pycorenlp\n",
            "  Building wheel for pycorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycorenlp: filename=pycorenlp-0.3.0-cp36-none-any.whl size=2143 sha256=92890fe2198e689e0911e6aef4f6dd52fb94a60759c195ede82db51eaced48a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/e9/2f/767a7b5f2e82d587a36143c04a21839b4b14bebfb89410d2d5\n",
            "Successfully built pycorenlp\n",
            "Installing collected packages: pycorenlp\n",
            "Successfully installed pycorenlp-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-UlO3Z1Jdgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOGDIR = '/tmp/log'\n",
        "get_ipython().system_raw(\n",
        "    \"\"\"java -mx8g -cp \"*\" \n",
        "    edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 ->timeout 60000 &\"\"\"\n",
        "    .format(LOGDIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_T-YLPlJdfg",
        "colab_type": "code",
        "outputId": "af47d654-6c03-4c90-f785-3ecee80c90e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-28 06:07:45--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 18.213.76.145, 52.201.33.182, 52.54.251.217, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|18.213.76.145|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  6.59MB/s    in 2.0s    \n",
            "\n",
            "2020-05-28 06:07:48 (6.59 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fe6LB2yJdaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 9001 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e1EUbHvJdZD",
        "colab_type": "code",
        "outputId": "d58dcc58-87f7-4bc6-8fc5-98c11095092b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://b7b1618c6213.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXWxYmnCJdUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pycorenlp import StanfordCoreNLP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crg5sep0JdTG",
        "colab_type": "code",
        "outputId": "57e491e0-6222-459e-978d-7f033671dcc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Install stanza; note that the prefix \"!\" is not needed if you are running in a terminal\n",
        "!pip install stanza\n",
        "\n",
        "# Import stanza\n",
        "import stanza"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/9c/60689521a971a57dd02d2925105efedefa9dccd76c9a0b92566683d43e89/stanza-1.0.1-py3-none-any.whl (193kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.10.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (46.3.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE3S-MrLJdKz",
        "colab_type": "code",
        "outputId": "35692b36-a59e-4933-850c-5f8ffe2477dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the Stanford CoreNLP Java library and unzip it to a ./corenlp folder\n",
        "!echo \"Downloading CoreNLP...\"\n",
        "!wget \"http://nlp.stanford.edu/software/stanford-corenlp-4.0.0.zip\" -O corenlp.zip\n",
        "!unzip corenlp.zip\n",
        "!mv ./stanford-corenlp-4.0.0 ./corenlp\n",
        "\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = \"./corenlp\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading CoreNLP...\n",
            "--2020-05-28 06:08:35--  http://nlp.stanford.edu/software/stanford-corenlp-4.0.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/software/stanford-corenlp-4.0.0.zip [following]\n",
            "--2020-05-28 06:08:35--  https://nlp.stanford.edu/software/stanford-corenlp-4.0.0.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 504479415 (481M) [application/zip]\n",
            "Saving to: ‘corenlp.zip’\n",
            "\n",
            "corenlp.zip         100%[===================>] 481.11M  21.1MB/s    in 31s     \n",
            "\n",
            "2020-05-28 06:09:06 (15.7 MB/s) - ‘corenlp.zip’ saved [504479415/504479415]\n",
            "\n",
            "Archive:  corenlp.zip\n",
            "   creating: stanford-corenlp-4.0.0/\n",
            "  inflating: stanford-corenlp-4.0.0/jaxb-impl-2.4.0-b180830.0438.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/RESOURCE-LICENSES  \n",
            "  inflating: stanford-corenlp-4.0.0/javax.activation-api-1.2.0-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/corenlp.sh  \n",
            "  inflating: stanford-corenlp-4.0.0/SemgrexDemo.java  \n",
            "  inflating: stanford-corenlp-4.0.0/stanford-corenlp-4.0.0.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/ejml-core-0.38-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/joda-time.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/jaxb-core-2.3.0.1.jar  \n",
            "   creating: stanford-corenlp-4.0.0/tokensregex/\n",
            "  inflating: stanford-corenlp-4.0.0/tokensregex/retokenize.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/tokensregex/color.input.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/tokensregex/color.properties  \n",
            "  inflating: stanford-corenlp-4.0.0/tokensregex/color.rules.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/input.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/javax.json-api-1.0-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/joda-time-2.10.5-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/README.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/xom.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/input.txt.xml  \n",
            "  inflating: stanford-corenlp-4.0.0/stanford-corenlp-4.0.0-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/CoreNLP-to-HTML.xsl  \n",
            "  inflating: stanford-corenlp-4.0.0/jollyday.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/slf4j-api.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/build.xml  \n",
            "  inflating: stanford-corenlp-4.0.0/Makefile  \n",
            "  inflating: stanford-corenlp-4.0.0/slf4j-simple.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/jaxb-api-2.4.0-b180830.0359.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/ejml-simple-0.38-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/ejml-ddense-0.38-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/input.txt.out  \n",
            "  inflating: stanford-corenlp-4.0.0/ejml-simple-0.38.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/jaxb-impl-2.4.0-b180830.0438-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/ShiftReduceDemo.java  \n",
            "  inflating: stanford-corenlp-4.0.0/StanfordDependenciesManual.pdf  \n",
            "  inflating: stanford-corenlp-4.0.0/pom.xml  \n",
            "   creating: stanford-corenlp-4.0.0/patterns/\n",
            "  inflating: stanford-corenlp-4.0.0/patterns/goldnames.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/patterns/names.txt  \n",
            " extracting: stanford-corenlp-4.0.0/patterns/goldplaces.txt  \n",
            " extracting: stanford-corenlp-4.0.0/patterns/places.txt  \n",
            " extracting: stanford-corenlp-4.0.0/patterns/otherpeople.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/patterns/presidents.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/patterns/stopwords.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/patterns/example.properties  \n",
            "  inflating: stanford-corenlp-4.0.0/stanford-corenlp-4.0.0-javadoc.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/ejml-core-0.38.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/jaxb-core-2.3.0.1-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/stanford-corenlp-4.0.0-models.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/StanfordCoreNlpDemo.java  \n",
            "   creating: stanford-corenlp-4.0.0/sutime/\n",
            "  inflating: stanford-corenlp-4.0.0/sutime/british.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/sutime/english.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/sutime/english.holidays.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/sutime/spanish.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/sutime/defs.sutime.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/LIBRARY-LICENSES  \n",
            "  inflating: stanford-corenlp-4.0.0/javax.activation-api-1.2.0.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/protobuf.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/ejml-ddense-0.38.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/jollyday-0.4.9-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/pom-java-11.xml  \n",
            "  inflating: stanford-corenlp-4.0.0/jaxb-api-2.4.0-b180830.0359-sources.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/LICENSE.txt  \n",
            "  inflating: stanford-corenlp-4.0.0/javax.json.jar  \n",
            "  inflating: stanford-corenlp-4.0.0/xom-1.3.2-sources.jar  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QrkjrGXJc7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import client module\n",
        "from stanza.server import CoreNLPClient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPCPEITmG4VI",
        "colab_type": "code",
        "outputId": "8e53cd6a-51dc-495b-d140-f168b66ddb4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner'], memory='4G', endpoint='http://localhost:9001')\n",
        "print(client)\n",
        "\n",
        "# Start the background server and wait for some time\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
        "client.start()\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<stanza.server.client.CoreNLPClient object at 0x7f6320f70860>\n",
            "Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-0f5fd2eb8d384d2a.props -preload tokenize,ssplit,pos,lemma,ner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMbR1gQsG4UP",
        "colab_type": "code",
        "outputId": "b44ae2c0-e7f2-4893-9f1c-5da2cb33c7f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Print background processes and look for java\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    285 java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-0f5fd2eb8d384d2a.props -preload tokenize,ssplit,pos,lemma,ner\n",
            "    315 /bin/bash -c ps -o pid,cmd | grep java\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvtRf4_JP4Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = StanfordCoreNLP('http://localhost:9001')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPcC4H8bQkbU",
        "colab_type": "code",
        "outputId": "77a081c1-7565-418d-d8fe-5a4aa1757192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2699, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRI6de5eQkzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " df['data'].replace('', np.nan, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwCx756cRcnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(subset=['data'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdyZRw-8RsFk",
        "colab_type": "code",
        "outputId": "21bc4f6d-7614-400d-c9cd-31997405833a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2672, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUYGMT-nR-3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df['Unnamed: 0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaWxVV6eSJgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjPsU-174lbC",
        "colab_type": "code",
        "outputId": "d3658288-fbaf-4cec-8135-2a3addda950c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2672, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGTB_1d7Xbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.assign(Stanford_score=np.nan,Stanford_sentiment=np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HrdHF8nP4l5",
        "colab_type": "code",
        "outputId": "9647d063-fb38-4089-dcf4-da8de1f8f61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(2624,2672):\n",
        "  res = nlp.annotate(df['data'][i],\n",
        "                    properties={\n",
        "                        'annotators': 'sentiment',\n",
        "                        'outputFormat': 'json',\n",
        "                        'timeout': 1000,\n",
        "                    })\n",
        "  for s in res[\"sentences\"]:\n",
        "      print(i)\n",
        "      print(\"%d: '%s': %s %s\" % (\n",
        "          s[\"index\"],\n",
        "          \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
        "          s[\"sentimentValue\"], s[\"sentiment\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2624\n",
            "0: 'before august when i told people i was running for congress they thought it was a joke when they saw me leadbyexam': 1 Negative\n",
            "2625\n",
            "0: 'blm skirts management failures asks congress to accelerate program collapse action item tue': 1 Negative\n",
            "2626\n",
            "0: 'more evidence the whitehouse and congress aren currently interested in another round phase of stimulus': 2 Neutral\n",
            "2627\n",
            "0: 'if americans can serve selflessly throughout the coronavirus crisis and if the white house can continue to go to work every d': 1 Negative\n",
            "2628\n",
            "0: 'priyankabusscam auto rickshaws ambulances small capacity school vans amp vehicles with expired fitness certificates were': 1 Negative\n",
            "2629\n",
            "0: 'uppolice detain state congress chief ajaykumarlallu': 2 Neutral\n",
            "2630\n",
            "0: 'retweet if u agree that photographing during the compulsion of the poor has been an old hobby of the gandhi family congr': 1 Negative\n",
            "2631\n",
            "0: 'just in in the list of buses submitted by the congress to the up government have been found to be buses while': 2 Neutral\n",
            "2632\n",
            "0: 'test it on congress so any possible adverse affects have an upside for the public for a change we know we will he': 2 Neutral\n",
            "2633\n",
            "0: 'identity thief httpstcoyjdqxrl sign up now and get free iastracoins no credit card needed mobile use': 2 Neutral\n",
            "2634\n",
            "0: 'this is just so satisfying to see pelosi swearing into congress will she rip up the bible after th': 3 Positive\n",
            "2635\n",
            "0: 'important congress can still right this ship but time is running out congress will have days from on or about may': 3 Positive\n",
            "2636\n",
            "0: 'how many buses did provided in congress ruling state maybe not even in all together': 1 Negative\n",
            "2637\n",
            "0: 'speakerpelosi you have had so much work done that you cant go in the sun to long are youd melt and your crack jaw is': 3 Positive\n",
            "2638\n",
            "0: 'shame on congress its leaders and its followers': 1 Negative\n",
            "2639\n",
            "0: 'vulturous eyes of congress are on pmcaresfund it was theirs by right': 3 Positive\n",
            "2640\n",
            "0: 'do nt be a dave identitytheft risk is real find out here what happened to daves house car and boat theft insu': 3 Positive\n",
            "2641\n",
            "0: 'do nt be a dave identitytheft risk is real find out here what happened to daves house car and boat theft': 1 Negative\n",
            "2642\n",
            "0: 'just in in the list of buses submitted by the congress to the up government have been found to be buses while': 2 Neutral\n",
            "2643\n",
            "0: 'congress cant speak truth cant listen truth cant digest truth cant face truth and if courageous journalist like': 3 Positive\n",
            "2644\n",
            "0: 'as they are filing fir against reporters an fir should be filed against pankaj punia': 2 Neutral\n",
            "2645\n",
            "0: 'just in in the list of buses submitted by the congress to the up government have been found to be buses while': 2 Neutral\n",
            "2646\n",
            "0: 'pb cm should explain why he is not proceeding against congress mlas madan lal jalalpur amp hardyal kamboj t': 1 Negative\n",
            "2647\n",
            "0: 'as per media reports the excise collection has gone down by rs crore in months of as compared to the budge': 1 Negative\n",
            "2648\n",
            "0: 'tell congress to protect wild horses from the blms reckless management plan sign an send here gt': 3 Positive\n",
            "2649\n",
            "0: 'ouragtcongress shall makenolaw respecting an establishmentofreligions or prohibiting the freeexercise': 2 Neutral\n",
            "2650\n",
            "0: 'million people have filed for unemployment and child hunger is on the risecongress the people need recurring sti': 1 Negative\n",
            "2651\n",
            "0: 'amen letpeopleprosper txlege congress': 2 Neutral\n",
            "2652\n",
            "0: 'everybody has been trying to figure out why this relationship between the us amp saudi arabia is so strangely close if': 2 Neutral\n",
            "2653\n",
            "0: 'whomever forwarded my mail to is getting indicted for mail fraud lapd fbi northfieldpolicedept senatefloor': 2 Neutral\n",
            "2654\n",
            "0: 'one of these issues can be solved in day supremecourt congress savelives': 2 Neutral\n",
            "2655\n",
            "0: 'that man never ever helped anyone but himself he stole a credit card and i just opened for the first time please a': 1 Negative\n",
            "2656\n",
            "0: 'reagan went to congress for permission and financing which one has to do in order to go to war congress said': 1 Negative\n",
            "2657\n",
            "0: 'dietary guidelines should include a bacon warning via': 1 Negative\n",
            "2658\n",
            "0: 'run for congress scott americans must beat the career politicians in the next election republicans': 2 Neutral\n",
            "2659\n",
            "0: 'stealing defeat from the jaws of victory should the democratic leadership in congress yet anoth': 2 Neutral\n",
            "2660\n",
            "0: 'forefathers say congress need to keep the law more in their hands covid coronaviruspandemic took a toll in ou': 2 Neutral\n",
            "2661\n",
            "0: 'forefathers say congress need to keep the law more in their hands covid coronaviruspandemic took a toll in': 2 Neutral\n",
            "2662\n",
            "0: 'antonio maino what a training guidelines and instructions from you': 2 Neutral\n",
            "2663\n",
            "0: 'tell congress to protect wild horses from the blms reckless management plan sign an send here gt': 3 Positive\n",
            "2664\n",
            "0: 'just in in the list of buses submitted by the congress to the up government have been found to be buses while': 2 Neutral\n",
            "2665\n",
            "0: 'facing the gravest us economiccrisis in decades treasury secretary steven mnuchin and federal reserve chair jer': 2 Neutral\n",
            "2666\n",
            "0: 'cant congress do anything to protect the nationalguard servicepeople so they can work through june and get t': 2 Neutral\n",
            "2667\n",
            "0: 'any dem in congress who does not see that ca went red after years and the rep in wi winning who votes for ano': 3 Positive\n",
            "2668\n",
            "0: 'corrupt congress hard at work did you vote for this stand alone unconstitutionality too or do you': 1 Negative\n",
            "2669\n",
            "0: 'in case anyone is wondering how the tx debate is going is killing it': 2 Neutral\n",
            "2670\n",
            "0: 'cant congress do anything to protect the nationalguard servicepeople so they can work through june': 2 Neutral\n",
            "2671\n",
            "0: 'any dem in congress who does not see that ca went red after years and the rep in wi winning who votes for ano': 3 Positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KahV6O3MSdFT",
        "colab_type": "code",
        "outputId": "6b485251-1dad-496c-b765-3832cbdbd8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for i in range(2624,2672):\n",
        "  res = nlp.annotate(df['data'][i],\n",
        "                    properties={\n",
        "                        'annotators': 'sentiment',\n",
        "                        'outputFormat': 'json',\n",
        "                        'timeout': 1000,\n",
        "                    })\n",
        "  for s in res[\"sentences\"]:\n",
        "          df['Stanford_score'][i]=s[\"sentimentValue\"]\n",
        "          df['Stanford_sentiment'][i]= s[\"sentiment\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vvoa8n9G32l",
        "colab_type": "code",
        "outputId": "09af6e81-0369-45ec-eea1-5133e94b00e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>tagged_usernames</th>\n",
              "      <th>Text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>data</th>\n",
              "      <th>pol_sub</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>Stanford_score</th>\n",
              "      <th>Stanford_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>11:47:00</td>\n",
              "      <td>['#bjp', '#rss']</td>\n",
              "      <td>['@any_morya:']</td>\n",
              "      <td>['big', 'shame', 'bjp', 'rss', 'tried', 'divide', 'hindu', 'muslim', 'sunlight', 'heat', 'keeping', 'daily', 'ramzan', 'fasting']</td>\n",
              "      <td>['big', 'shame', 'bjp', 'rss', 'tried', 'divide', 'hindu', 'muslim', 'sunlight', 'heat', 'keeping', 'daily', 'ramzan', 'fasting']</td>\n",
              "      <td>its big shame to bjp rss who tried to divide hindu muslim  in such sunlight and heat keeping their daily ramzan fasting</td>\n",
              "      <td>Sentiment(polarity=0.0, subjectivity=0.19999999999999998)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>11:47:00</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@milligazette:', '@muslimmirror']</td>\n",
              "      <td>['fir', 'news', 'website', '.', 'according', 'gujarat', 'police', 'day', 'shahpur', 'stone-pelting', 'video']</td>\n",
              "      <td>['fir', 'news', 'website', '.', 'according', 'gujarat', 'police', 'day', 'shahpur', 'stone-pelting', 'video']</td>\n",
              "      <td>fir against  news website according to gujarat police a day after the shahpur stonepelting a video was</td>\n",
              "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>11:48:00</td>\n",
              "      <td>['#bjp', '#gujrati', '#haridwar', '#covid__19.are']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['bjp', 'govt', 'allows', '18', 'luxury', 'coaches', 'gujrati', 'pilgrims', 'haridwar', 'gujarat', 'amidst', 'covid__19.are', 'ppl']</td>\n",
              "      <td>['bjp', 'govt', 'allows', '18', 'luxury', 'coaches', 'gujrati', 'pilgrims', 'haridwar', 'gujarat', 'amidst', 'covid__19.are', 'ppl']</td>\n",
              "      <td>bjp govt allows  luxury coaches for gujrati pilgrims from haridwar to gujarat amidst covid  are the ppl of</td>\n",
              "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>11:46:00</td>\n",
              "      <td>['#bjp', '#rss', '#rss_terrorists']</td>\n",
              "      <td>['@muslimmirror:']</td>\n",
              "      <td>['armed', 'bjp', 'rss', 'activists', 'police', 'shahpur', 'ahmedabad', 'rss_terrorists']</td>\n",
              "      <td>['armed', 'bjp', 'rss', 'activists', 'police', 'shahpur', 'ahmedabad', 'rss_terrorists']</td>\n",
              "      <td>armed bjp rss activists with police in shahpur  ahmedabad rss terrorists</td>\n",
              "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>11:46:00</td>\n",
              "      <td>['#hindurashtra', '#india', '#hindus', '#modi.']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['aspirants', 'hindurashtra', 'india', 'must', 'see', 'pathetic', 'conditions', 'poor', 'hindus', 'modi', '.', 'worst']</td>\n",
              "      <td>['aspirants', 'hindurashtra', 'india', 'must', 'see', 'pathetic', 'conditions', 'poor', 'hindus', 'modi', '.', 'worst']</td>\n",
              "      <td>aspirants of hindurashtra in india must see pathetic conditions of poor hindus under modi in worst</td>\n",
              "      <td>Sentiment(polarity=-0.7999999999999999, subjectivity=0.8666666666666667)</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2667</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>01:27:00</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ronnielouise2:']</td>\n",
              "      <td>['dem', 'congress', 'see', 'ca25', 'went', 'red', '22', 'years', 'rep', 'wi', 'winning', 'votes', 'ano']</td>\n",
              "      <td>['dem', 'congress', 'see', 'ca25', 'went', 'red', '22', 'years', 'rep', 'wi', 'winning', 'votes', 'ano']</td>\n",
              "      <td>any dem in congress who does not see that ca went red after  years and the rep in wi winning who votes for ano</td>\n",
              "      <td>Sentiment(polarity=0.25, subjectivity=0.375)</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2668</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>01:27:00</td>\n",
              "      <td>['#congress']</td>\n",
              "      <td>['@vernbuchanan']</td>\n",
              "      <td>['corrupt', 'congress', 'hard', 'work', '.', 'vote', 'stand', 'alone', 'unconstitutionality']</td>\n",
              "      <td>['corrupt', 'congress', 'hard', 'work', '.', 'vote', 'stand', 'alone', 'unconstitutionality']</td>\n",
              "      <td>corrupt congress hard at work  did you vote for this stand alone unconstitutionality too  or do you</td>\n",
              "      <td>Sentiment(polarity=-0.39583333333333337, subjectivity=0.7708333333333333)</td>\n",
              "      <td>-0.395833</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2669</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>01:26:00</td>\n",
              "      <td>['#tx10']</td>\n",
              "      <td>['@harrisdemocrats', '@priteshgandhimd']</td>\n",
              "      <td>['case', 'anyone', 'wondering', 'tx10', 'debate', 'going', '...', 'killing', '.']</td>\n",
              "      <td>['case', 'anyone', 'wondering', 'tx10', 'debate', 'going', '...', 'killing', '.']</td>\n",
              "      <td>in case anyone is wondering how the  tx debate is going   is killing it</td>\n",
              "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2670</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>01:24:00</td>\n",
              "      <td>['#congress', '#nationalguard']</td>\n",
              "      <td>['@maddow:']</td>\n",
              "      <td>['.', 'cant', 'congress', 'anything', 'protect', 'nationalguard', 'servicepeople', 'work', 'june', '25']</td>\n",
              "      <td>['.', 'cant', 'congress', 'anything', 'protect', 'nationalguard', 'servicepeople', 'work', 'june', '25']</td>\n",
              "      <td>cant congress do anything to protect the nationalguard servicepeople so they can work through june</td>\n",
              "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2671</th>\n",
              "      <td>2020-05-20</td>\n",
              "      <td>01:24:00</td>\n",
              "      <td>[]</td>\n",
              "      <td>['@ronnielouise2:']</td>\n",
              "      <td>['dem', 'congress', 'see', 'ca25', 'went', 'red', '22', 'years', 'rep', 'wi', 'winning', 'votes', 'ano']</td>\n",
              "      <td>['dem', 'congress', 'see', 'ca25', 'went', 'red', '22', 'years', 'rep', 'wi', 'winning', 'votes', 'ano']</td>\n",
              "      <td>any dem in congress who does not see that ca went red after  years and the rep in wi winning who votes for ano</td>\n",
              "      <td>Sentiment(polarity=0.25, subjectivity=0.375)</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2672 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date      Time  ... Stanford_score Stanford_sentiment\n",
              "0     2020-05-20  11:47:00  ...            1.0           Negative\n",
              "1     2020-05-20  11:47:00  ...            2.0            Neutral\n",
              "2     2020-05-20  11:48:00  ...            2.0            Neutral\n",
              "3     2020-05-20  11:46:00  ...            2.0            Neutral\n",
              "4     2020-05-20  11:46:00  ...            1.0           Negative\n",
              "...          ...       ...  ...            ...                ...\n",
              "2667  2020-05-20  01:27:00  ...            3.0           Positive\n",
              "2668  2020-05-20  01:27:00  ...            1.0           Negative\n",
              "2669  2020-05-20  01:26:00  ...            2.0            Neutral\n",
              "2670  2020-05-20  01:24:00  ...            2.0            Neutral\n",
              "2671  2020-05-20  01:24:00  ...            3.0           Positive\n",
              "\n",
              "[2672 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwsn22bRIeUK",
        "colab_type": "text"
      },
      "source": [
        "**Save the final csv file to 'last1.csv'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTSgvss0G3tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('last1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}